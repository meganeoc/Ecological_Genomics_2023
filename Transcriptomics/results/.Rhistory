hello
3+7
4^3-5
airTemp<-c(34,35,42,48,39)
print(airTemp)
summary(airTemp)
batAbundance<-c(100,104,98,132,138,150)
summary(batAbundance)
plot(x=airTemp, y=batAbundance)
plot(x=airTemp, y=batAbundance)
airTemp<-c(32,34,35,37,39,40)
plot(x=airTemp, y=batAbundance)
plot(x=airTemp, y=batAbundance,type="o")
ANOVADiameter <- aov(GoldenrodRawData$Diameter ~ GoldenrodRawData$SpeciesID)
# the par() function customizes many features of your graphs
# make a copy of current graphical parameter values
opar <- par()
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
SC <- subset(GoldenrodRawData, SpeciesID == "SC")
SR <- subset(GoldenrodRawData, SpeciesID == "SR")
# the par() function customizes many features of your graphs
# make a copy of current graphical parameter values
opar <- par()
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
SC <- subset(GoldenrodRawData, SpeciesID == "SC")
SR <- subset(GoldenrodRawData, SpeciesID == "SR")
# the par() function customizes many features of your graphs
# make a copy of current graphical parameter values
opar <- par()
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
SC <- subset(GoldenrodRawData, SpeciesID == "SC")
SR <- subset(GoldenrodRawData, SpeciesID == "SR")
SG <- subset(GoldenrodRawData, SpeciesID == "SG")
## Summary statistic values
summary(SC)
summary(SR)
library(readr)
Goldenrod_RawData <- read_csv("Downloads/Goldenrod_RawData.csv")
View(Goldenrod_RawData)
# the par() function customizes many features of your graphs
# make a copy of current graphical parameter values
opar <- par()
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
SC <- subset(GoldenrodRawData, SpeciesID == "SC")
SR <- subset(GoldenrodRawData, SpeciesID == "SR")
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
View(Goldenrod_RawData)
# the par() function customizes many features of your graphs
# make a copy of current graphical parameter values
opar <- par()
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
SC <- subset(GoldenrodRawData, SpeciesID == "SC")
SR <- subset(GoldenrodRawData, SpeciesID == "SR")
SG <- subset(GoldenrodRawData, SpeciesID == "SG")
# the par() function customizes many features of your graphs
# make a copy of current graphical parameter values
opar <- par()
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
SC <- subset(GoldenrodRawData, SpeciesID == "SC")
par(mfrow=c(3,1))
plot(SC$Diameter ~SC$Height)
#CoefSC <- cor(SC$Diameter, SC$Height)
#don't worry about lm now, it is to draw a line on the graph
regressionSC = lm(SC$Diameter ~SC$Height)
abline(regressionSC, col = "green")
legend("topleft", bty="n", legend= "r =LOOK AT CoefSC in console")
#SR
plot(SR$Diameter ~ SR$Height)
regressionSR = lm(SR$Diameter ~SR$Height)
# the par() function customizes many features of your graphs
# make a copy of current graphical parameter values
opar <- par()
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
SC <- subset(GoldenrodRawData, SpeciesID == "SC")
SR <- subset(GoldenrodRawData, SpeciesID == "SR")
SG <- subset(GoldenrodRawData, SpeciesID == "SG")
## Summary statistic values
summary(SC)
# the par() function customizes many features of your graphs
# make a copy of current graphical parameter values
opar <- par()
#file.choose()
GoldenrodRawData <- read.csv(file = "Goldenrod_RawData.csv")
BiocManager::install("DESeq2")
library(DESeq2)
# Load the package
library(WGCNA);
?DESeq2
??DESeq2
library(DESeq2)
install.packages("locfit")
library(DESeq2)
setwd("~/Desktop/Ecological_Genomics_2023/Transcriptomics/results")
install.packages("WGCNA")
# Load the package
library(WGCNA);
install.packages("GO.db")
# Load the package
library(WGCNA);
# The following setting is important, do not omit.
options(stringsAsFactors = FALSE);
library(DESeq2)
library(ggplot2)
library(tidyverse)
library(CorLevelPlot)
library(gridExtra)
library(Rmisc)
library(corrplot)
install.packages("CorLevelPlot")
install.packages("remotes")
remotes::install_github("kevinblighe/CorLevelPlot")
library(CorLevelPlot)
library(gridExtra)
library(Rmisc)
# Import the counts matrix
countsTable <- read.table("salmon.isoform.counts.matrix.filteredAssembly", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # bc DESeq2 doesn't like decimals (and Salmon outputs data with decimals)
head(countsTableRound)
#import the sample discription table
conds <- read.delim("ahud_samples_R.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1)
head(conds)
##################################################
# Let's see how many reads we have from each sample
colSums(countsTableRound)
mean(colSums(countsTableRound))
countsTable <- read.table("salmon.isoform.counts.matrix.filteredAssembly", header=TRUE, row.names=1)
countsTable <- read.table("Ahud_trait_data.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # bc DESeq2 doesn't like decimals (and Salmon outputs data with decimals)
head(countsTableRound)
# Import the counts matrix
countsTable <- read.table("salmon.isoform.counts.matrix", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # bc DESeq2 doesn't like decimals (and Salmon outputs data with decimals)
head(countsTableRound)
#import the sample discription table
conds <- read.delim("ahud_samples_R.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1)
head(conds)
# Let's see how many reads we have from each sample
colSums(countsTableRound)
mean(colSums(countsTableRound))
barplot(colSums(countsTableRound), names.arg=colnames(countsTableRound),cex.names=0.5, las=3,ylim=c(0,21000000))
abline(h=mean(colSums(countsTableRound)), col="blue", lwd=2)
# the average number of counts per gene
rowSums(countsTableRound)
mean(rowSums(countsTableRound)) # [1] 2245.401
median(rowSums(countsTableRound)) # [1] 117
apply(countsTableRound,2,mean) # 2 in the apply function does the action across columns
apply(countsTableRound,1,mean) # 1 in the apply function does the action across rows
hist(apply(countsTableRound,1,mean),xlim=c(0,1000), ylim=c(0,300000),breaks=10000)
dds <- DESeqDataSetFromMatrix(countData = countsTableRound, colData=conds,
design= ~ treatment + generation)
dim(dds)
dds <- dds[rowSums(counts(dds) >= 30) >= 28,]
nrow(dds)
# Run the DESeq model to test for differential gene expression
dds <- DESeq(dds)
# List the results you've generated
resultsNames(dds)
# Import the counts matrix
countsTable <- read.table("salmon.isoform.counts.matrix.filteredAssembly", header=TRUE, row.names=1)
# Import the counts matrix
countsTable <- read.table("Ahud_trait_data.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # bc DESeq2 doesn't like decimals (and Salmon outputs data with decimals)
head(countsTableRound)
#import the sample discription table
conds <- read.delim("ahud_samples_R.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1)
head(conds)
##################################################
# Let's see how many reads we have from each sample
colSums(countsTableRound)
mean(colSums(countsTableRound))
barplot(colSums(countsTableRound), names.arg=colnames(countsTableRound),cex.names=0.5, las=3,ylim=c(0,20000000))
abline(h=mean(colSums(countsTableRound)), col="blue", lwd=2)
# the average number of counts per gene
rowSums(countsTableRound)
mean(rowSums(countsTableRound)) # [1] 6076.078 - hudsonica genes, 2269 - hudsonica isoform, 8218 - hudsonica filtered
median(rowSums(countsTableRound)) # [1] 582 - hudsonica, 109 - hudsonica isoforms, 377 - hudsonica filtered
apply(countsTableRound,2,mean) # 2 in the apply function does the action across columns
apply(countsTableRound,1,mean) # 1 in the apply function does the action across rows
hist(apply(countsTableRound,1,mean),xlim=c(0,1000), ylim=c(0,50000),breaks=10000)
dds <- DESeqDataSetFromMatrix(countData = countsTableRound, colData=conds,
design= ~ generation + treatment)
sample_metadata = read.table(file = "Ahud_trait_data.txt",header=T, row.names = 1)
countsTable <- read.table("Ahud_trait_data.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # bc DESeq2 doesn't like decimals (and Salmon outputs data with decimals)
countsTable <- read.table("salmon.isoform.counts.matrix.filteredAssembly", header=TRUE, row.names=1)
countsTable <- read.table("salmon.isoform.counts.matrix.filteredAssembly", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # bc DESeq2 doesn't like decimals (and Salmon outputs data with decimals)
head(countsTableRound)
sample_metadata = read.table(file = "Ahud_trait_data.txt",header=T, row.names = 1)
dds <- DESeqDataSetFromMatrix(countData = countsTableRound, colData=sample_metadata,
design= ~ 1)
dds <- DESeqDataSetFromMatrix(countData = countsTableRound, colData=sample_metadata,
design= ~ 1)
dim(dds)
dds <- dds[rowSums(counts(dds) >= 15) >= 28,]
nrow(dds)
# Run the DESeq model to test for differential gene expression
dds <- DESeq(dds)
gsg <- goodSamplesGenes(t(countsTable))
summary(gsg)
gsg$allOK
table(gsg$goodGenes)
table(gsg$goodSamples)
# detect outlier samples - hierarchical clustering - method 1
htree <- hclust(dist(t(countsTable)), method = "average")
plot(htree)
pca <- prcomp(t(countsTable))
pca.dat <- pca$x
pca.var <- pca$sdev^2
pca.var.percent <- round(pca.var/sum(pca.var)*100, digits = 2)
pca.dat <- as.data.frame(pca.dat)
ggplot(pca.dat, aes(PC1, PC2)) +
geom_point() +
geom_text(label = rownames(pca.dat)) +
labs(x = paste0('PC1: ', pca.var.percent[1], ' %'),
y = paste0('PC2: ', pca.var.percent[2], ' %'))
colData <- row.names(sample_metadata)
# making the rownames and column names identical
all(rownames(colData) %in% colnames(countsTableRound)) # to see if all samples are present in both
all(rownames(colData) == colnames(countsTableRound))  # to see if all samples are in the same order
# perform variance stabilization
dds_norm <- vst(dds)
# get normalized counts
norm.counts <- assay(dds_norm) %>%
t()
colData <- row.names(sample_metadata)
# making the rownames and column names identical
all(rownames(colData) %in% colnames(countsTableRound)) # to see if all samples are present in both
all(rownames(colData) == colnames(countsTableRound))  # to see if all samples are in the same order
##############################################################################
# CHECK QUALITY OF DATA BY SAMPLE CLUSTERING AND VISUALIZATION
# 4. Network Construction  ---------------------------------------------------
# Choose a set of soft-thresholding powers
power <- c(c(1:10), seq(from = 12, to = 50, by = 2))
# Call the network topology analysis function; this step takes a couple minutes
sft <- pickSoftThreshold(norm.counts,
powerVector = power,
networkType = "signed",
verbose = 5)
sft.data <- sft$fitIndices
a1 <- ggplot(sft.data, aes(Power, SFT.R.sq, label = Power)) +
geom_point() +
geom_text(nudge_y = 0.1) +
geom_hline(yintercept = 0.8, color = 'red') +
labs(x = 'Power', y = 'Scale free topology model fit, signed R^2') +
theme_classic()
a2 <- ggplot(sft.data, aes(Power, mean.k., label = Power)) +
geom_point() +
geom_text(nudge_y = 0.1) +
labs(x = 'Power', y = 'Mean Connectivity') +
theme_classic()
grid.arrange(a1, a2, nrow = 2)
# convert matrix to numeric
norm.counts[] <- sapply(norm.counts, as.numeric)
soft_power <- 6
temp_cor <- cor
cor <- WGCNA::cor # use the 'cor' function from the WGCNA package
# this step also takes a few minutes; ideally your maxBlockSize is larger than your number of genes to run the memory-intensive network construction all at once.
bwnet <- blockwiseModules(norm.counts,
maxBlockSize = 26000,
minModuleSize = 30,
reassignThreshold=0,
TOMType = "signed",
power = soft_power,
mergeCutHeight = 0.25,
numericLabels = F,
randomSeed = 1234,
verbose = 3)
cor <- temp_cor
##############################################################################
# CHECK QUALITY OF DATA BY SAMPLE CLUSTERING AND VISUALIZATION
# 4. Network Construction  ---------------------------------------------------
# Choose a set of soft-thresholding powers
power <- c(c(1:10), seq(from = 12, to = 50, by = 2))
# Call the network topology analysis function; this step takes a couple minutes
sft <- pickSoftThreshold(norm.counts,
powerVector = power,
networkType = "signed",
verbose = 5)
library(WGCNA)
##############################################################################
# CHECK QUALITY OF DATA BY SAMPLE CLUSTERING AND VISUALIZATION
# 4. Network Construction  ---------------------------------------------------
# Choose a set of soft-thresholding powers
power <- c(c(1:10), seq(from = 12, to = 50, by = 2))
# Call the network topology analysis function; this step takes a couple minutes
sft <- pickSoftThreshold(norm.counts,
powerVector = power,
networkType = "signed",
verbose = 5)
sft.data <- sft$fitIndices
a1 <- ggplot(sft.data, aes(Power, SFT.R.sq, label = Power)) +
geom_point() +
geom_text(nudge_y = 0.1) +
geom_hline(yintercept = 0.8, color = 'red') +
labs(x = 'Power', y = 'Scale free topology model fit, signed R^2') +
theme_classic()
# Load the package
library(WGCNA);
##############################################################################
# CHECK QUALITY OF DATA BY SAMPLE CLUSTERING AND VISUALIZATION
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("GO.db")
##############################################################################
# CHECK QUALITY OF DATA BY SAMPLE CLUSTERING AND VISUALIZATION
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("GO.db")
force = TRUE
BiocManager::install("GO.db")
library(igraph)
library(deldir)
library(KernSmooth)
library(Matrix)
library(nlme)
library(RcppArmadillo)
library(mgcv)
library(classInt)
##############################################################################
# CHECK QUALITY OF DATA BY SAMPLE CLUSTERING AND VISUALIZATION
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("GO.db")
install.packages("BiocManager") force = TRUE
BiocManager::install("GO.db")
##############################################################################
# CHECK QUALITY OF DATA BY SAMPLE CLUSTERING AND VISUALIZATION
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("GO.db", force = TRUE)
# 4. Network Construction  ---------------------------------------------------
# Choose a set of soft-thresholding powers
power <- c(c(1:10), seq(from = 12, to = 50, by = 2))
# Call the network topology analysis function; this step takes a couple minutes
sft <- pickSoftThreshold(norm.counts,
powerVector = power,
networkType = "signed",
verbose = 5)
sft.data <- sft$fitIndices
a1 <- ggplot(sft.data, aes(Power, SFT.R.sq, label = Power)) +
geom_point() +
geom_text(nudge_y = 0.1) +
geom_hline(yintercept = 0.8, color = 'red') +
labs(x = 'Power', y = 'Scale free topology model fit, signed R^2') +
theme_classic()
a2 <- ggplot(sft.data, aes(Power, mean.k., label = Power)) +
geom_point() +
geom_text(nudge_y = 0.1) +
labs(x = 'Power', y = 'Mean Connectivity') +
theme_classic()
##############################################################################
# CHECK QUALITY OF DATA BY SAMPLE CLUSTERING AND VISUALIZATION
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("impute")
##############################################################################
# CHECK QUALITY OF DATA BY SAMPLE CLUSTERING AND VISUALIZATION
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("impute", force = TRUE)
install.packages(c("classInt", "deldir", "Hmisc", "igraph", "KernSmooth", "Matrix", "mgcv", "nlme", "RcppArmadillo"))
